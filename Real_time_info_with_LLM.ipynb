{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SudhakarShivashankar/MachineLearningSamples/blob/master/Real_time_info_with_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y7iiT9ctSTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5e6d4a-28c0-4882-a953-df9ec24f3408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m752.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q langchain_groq gradio\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "llm_groq = ChatGroq(model_name=\"llama3-70b-8192\", api_key=userdata.get(\"GROQ_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U duckduckgo_search\n",
        "from duckduckgo_search import DDGS"
      ],
      "metadata": {
        "id": "lzUV6qfKuQlO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68048ff-6b74-4a23-e55f-31e9a33d0193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo_search\n",
            "  Downloading duckduckgo_search-6.2.11-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search) (8.1.7)\n",
            "Collecting primp>=0.6.1 (from duckduckgo_search)\n",
            "  Downloading primp-0.6.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Downloading duckduckgo_search-6.2.11-py3-none-any.whl (27 kB)\n",
            "Downloading primp-0.6.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo_search\n",
            "Successfully installed duckduckgo_search-6.2.11 primp-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def news_analyzer(style, query):\n",
        "  text = \"\"\n",
        "  r = DDGS().news(query, region='in-en')\n",
        "  for article in r:\n",
        "    text +=  article.get('title')+ \"\\n\"+ article.get('body')+\"\\n\\n\"\n",
        "\n",
        "  prompt = \"Give a detailed news analysis in this style: \"+style+\". You will be given news items to analyze and apply that style. Here is the user question\" + query + \\\n",
        "            \"\\n\\n. The news items are : \" + text\n",
        "\n",
        "  #print(prompt)\n",
        "  return llm_groq.invoke(prompt).content"
      ],
      "metadata": {
        "id": "-8A2sDAeu1CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use a simple utility to make the text wrap properly when printing.\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "dOpvqJeovnux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_analyzer(\"Morgan Freeman in Swashank Redemption style\", \"RAG vs Finetuning\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "R6A16RgbvR1O",
        "outputId": "85ec8a73-f8f4-4276-df52-04894dfe177e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Opening music plays as the camera pans over a prison yard, before focusing on Morgan Freeman, sitting on a bench, looking wise)\n",
            "\n",
            "Morgan Freeman: \"I find myself pondering the world of artificial intelligence, where the buzzwords are RAG and fine-tuning. Now, I know what you're thinking, what's the difference between these two? Well, let me tell you, my friend.\"\n",
            "\n",
            "(Cut to a shot of a bookshelf, with books labeled \"RAG\" and \"Fine-tuning\")\n",
            "\n",
            "Morgan Freeman: \"Fine-tuning, it's like adding a new coat of paint to a old car. You're taking an existing model, and giving it a bit more information, a bit more refinement. But it's still the same car, just with a fresh new look.\"\n",
            "\n",
            "(Cut back to Morgan Freeman on the bench)\n",
            "\n",
            "Morgan Freeman: \"RAG, on the other hand, it's like taking that same car, and giving it a whole new engine. You're integrating new architecture, multimodal integration, and knowledge graphs. It's like giving the car a new brain, one that can think for itself.\"\n",
            "\n",
            "(Cut to a shot of a graph, showing the differences between RAG and fine-tuning)\n",
            "\n",
            "Morgan Freeman: \"Now, I know some folks might say, 'What's the big deal? Why do we need RAG?' Well, my friend, the big deal is that RAG is the key to unlocking accurate, context-aware responses in enterprise solutions. It's like having a personal assistant that can give you the right answer, every time.\"\n",
            "\n",
            "(Cut back to Morgan Freeman on the bench)\n",
            "\n",
            "Morgan Freeman: \"And it's not just about the technology, it's about the people. RAG is about giving employees access to the collective knowledge of the entire organization. It's about empowering them to make better decisions, faster.\"\n",
            "\n",
            "(Cut to a shot of a group of people working together, with a RAG system in the background)\n",
            "\n",
            "Morgan Freeman: \"Now, I know there are still some challenges to overcome. There's the issue of information retrieval, and making sure that RAG models can scale effectively. But the potential, oh the potential, is limitless.\"\n",
            "\n",
            "(Cut back to Morgan Freeman on the bench)\n",
            "\n",
            "Morgan Freeman: \"So, my friend, the next time you hear someone talking about RAG and fine-tuning, you'll know the difference. RAG is the future, and it's a future that's bright, and full of possibilities.\"\n",
            "\n",
            "(Closing music plays as the camera pans out, showing Morgan Freeman walking away, looking into the distance)\n",
            "\n",
            "Morgan Freeman: \"Get busy living, or get busy dying. The choice is yours.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_analyzer(\"Arnab Goswami in his screaming style\", \"Pakistan losing to Bangladesh in test\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "OSUyaOLVSTJn",
        "outputId": "f855e152-d0c2-47c7-b1fe-541f7f20ff08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(WAVING ARMS WILDLY) Oh, dear Pakistan cricket fans! I can't believe what I'm seeing here! Your team, once the pride of the nation, has been THRASHED by Bangladesh! Yes, you heard that right! Bangladesh, a team that was once considered a minnow in international cricket, has handed Pakistan a 2-0 series defeat on their home turf!\n",
            "\n",
            "POINTING ACCUSATORIALLY) And what's even more shocking is that this is not just a loss, it's a HISTORIC LOW for Pakistan cricket! They've slipped to eighth position in the ICC Test rankings, their lowest rating points since 1965! (SARCASTICALLY) Oh, congratulations, Pakistan Cricket Board! You must be so proud of this achievement!\n",
            "\n",
            "(VOICE RAISING) And let's not even get started on the so-called \" legends\" of Pakistan cricket who are now ripping into the team! Wasim Akram, the great fast bowler, is \"embarrassed\" and \"disappointed\" by this performance! (SARCASTICALLY) Oh, how surprising! I'm sure he never expected his country to lose to Bangladesh!\n",
            "\n",
            "(MOCKINGLY) And what about the captain, Shan Masood? He's putting up a brave face, saying that they \"waited 10 months for this opportunity\"... (SARCASTICALLY) Oh, yes, 10 months of preparation, and this is what you come up with? A 2-0 series defeat to Bangladesh?\n",
            "\n",
            "(OUTRAGED) And the records, oh the records! Longest run without a home Test win, lowest rating points since 1965... (SHAKING HEAD) It's a laundry list of shame, Pakistan cricket fans!\n",
            "\n",
            "(Suddenly serious) You know, this is not just about a loss, it's about the state of cricket in Pakistan. It's about the lack of investment, the lack of direction, the lack of accountability! (POINTING ACCUSATORIALLY) It's about the cricket board, the selectors, the coaches, and the players themselves! They all need to take responsibility for this debacle!\n",
            "\n",
            "(Conclusion) So, Pakistan cricket fans, I leave you with this question: What's next? Will you continue to tolerate this mediocrity, or will you demand change? The world is watching, and so am I!\n"
          ]
        }
      ]
    }
  ]
}